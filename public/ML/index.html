<!DOCTYPE html>
<html lang="zh-tw" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>MLs | Rain Hu&#39;s Workspace</title>
<meta name="keywords" content="">
<meta name="description" content="MLs - Rain Hu&#39;s Workspace">
<meta name="author" content="Rain Hu, intervarrain, 陣雨">
<link rel="canonical" href="http://localhost:1313/ml/">
<meta name="google-site-verification" content="XYZabc">
<meta name="msvalidate.01" content="XYZabc">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b1c88c40153536920661ce82732db8841c2d140e1e179d3d1d9d723e6db8c980.css" integrity="sha256-sciMQBU1NpIGYc6Ccy24hBwtFA4eF509HZ1yPm24yYA=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/images/rain.png">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/images/rain.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/images/rain.png">
<link rel="apple-touch-icon" href="http://localhost:1313/images/rain.png">
<link rel="mask-icon" href="http://localhost:1313/images/rain.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/ml/index.xml">
<link rel="alternate" hreflang="zh-tw" href="http://localhost:1313/ml/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<script src="https://utteranc.es/client.js"
    repo="intervalrain.github.io"
    issue-term="pathname"
    label="Comment"
    theme="github-light"
    crossorigin="anonymous"
    async>
</script><meta property="og:url" content="http://localhost:1313/ml/">
  <meta property="og:site_name" content="Rain Hu&#39;s Workspace">
  <meta property="og:title" content="MLs">
  <meta property="og:description" content="Rain Hu 記錄生活、工作、學習、個人創作的空間，包含了音樂創作、文字創作、演算法筆記、資工學習資料、架站資料、程式語言筆記、Leetcode 解題分析等各式各樣的資訊">
  <meta property="og:locale" content="zh-tw">
  <meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MLs">
<meta name="twitter:description" content="Rain Hu 記錄生活、工作、學習、個人創作的空間，包含了音樂創作、文字創作、演算法筆記、資工學習資料、架站資料、程式語言筆記、Leetcode 解題分析等各式各樣的資訊">
      <meta name="twitter:site" content="@intervalrain">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "MLs",
      "item": "http://localhost:1313/ml/"
    }
  ]
}
</script>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Rain Hu&#39;s Workspace (Alt + H)">
                <img src="http://localhost:1313/images/rain.png" alt="" aria-label="logo"
                    height="35">Rain Hu&#39;s Workspace</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/search" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/aboutme" title="About me">
                    <span>About me</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/csharp/csharp" title="C#">
                    <span>C#</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/csindex" title="CS">
                    <span>CS</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/leetcode" title="LeetCode">
                    <span>LeetCode</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header"><div class="breadcrumbs"><a href="http://localhost:1313/">首頁</a></div>
  <h1>
    MLs
  </h1>
</header>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">[ML] 選擇 loss function/ optimizer/ metrics
    </h2>
  </header>
  <div class="entry-content">
    <p>建構模型 Dense(units, activation) units 為 output_size，keras 已經處理好自動計算 input_size 的部分。 activation function relu: Rectified Linear Unit, ReLU softmax: 對陣列中所有元素做自然對數取值後，在做 normalize，目的是放大最大權重的元素，並且將所有值換成 0~1 的值，意義類似機率。 model.keras.Sequential([ Dense(32, activation=&#34;relu&#34;), Dense(64, activation=&#34;relu&#34;), Dense(32, activation=&#34;relu&#34;), Dense(10, activation=&#34;softmax&#34;), ]) 編譯 損失函數(目標函數) loss function CategoricalCrossentropy SparseCategoricalCrossentropy BinaryCrossentropy MeanSquareError KLDivergence CosineSimilarity … 優化器 optimizer SGD (可搭配 momemtum) RMSprop Adam Adagrad … 評量指標 metrics CategoricalAccuracy SparseCategoricalAccuracy BinaryAccuracy AUC Precision Recall … 以下範例兩種型式都可以。其中物件的用法可以使用客製化的條件。
model.compile(optimizer=&#34;rmsprop&#34;, loss=&#34;mean_square_error&#34;, metics=[&#34;accuracy&#34;]) model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-4), loss=keras.meanSquaredError(), metrics=[keras.metrics.BinaryAccuracy]) 洗牌 收集完資料之後，我們目的並非只在訓練資料上取得良好的模型，而是要取得在大部分狀況下都表現良好的模型。 故我們需要將收集完的資料分成訓練集與驗證集。 以下透過 np.random.permutation() ，與 slice 來對資料做抽樣。 indices_permutation = np.random.permutation(len(data)) shuffled_inputs = data[indices_permutation] shuffled_targets = labels[indices_permutation] num_validation_samples = int(0.3 * len(data)) val_inputs = shuffled_inputs[:num_validation_samples] val_targets = shuffled_targets[:num_validation_samples] training_inputs = shuffled_inputs[num_validation_samples:] training_targets = shuffled_targets[num_validation_samples:] model.fit( training_inputs, training_targets, epochs=5, batch_size=16, validation_data=(val_inputs, val_targets) ) </p>
  </div>
  <footer class="entry-footer"><span title='2024-02-14 15:39:25 +0800 CST'>February 14, 2024</span>&nbsp;·&nbsp;1 分鐘&nbsp;·&nbsp;Rain Hu</footer>
  <a class="entry-link" aria-label="post link to [ML] 選擇 loss function/ optimizer/ metrics" href="http://localhost:1313/ml/optimizer/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">[ML] General guide on ML
    </h2>
  </header>
  <div class="entry-content">
    <p> Loss on training data large: model bias -&gt; add features optimization -&gt; change optimization methods small: loss on testing data large: overfitting: (1) more training data, data augmentation (2) make model simpler small: mismatch </p>
  </div>
  <footer class="entry-footer"><span title='2024-01-14 14:31:56 +0800 CST'>January 14, 2024</span>&nbsp;·&nbsp;1 分鐘&nbsp;·&nbsp;Rain Hu</footer>
  <a class="entry-link" aria-label="post link to [ML] General guide on ML" href="http://localhost:1313/ml/general_guide/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">[ML] sample1 - 手寫數字辨識
    </h2>
  </header>
  <div class="entry-content">
    <p>MNIST NIST(National Insitute of Standards and Technology) 是美國國家標準與技術研究院，MNIST 是由 NIST 所提供的一組經典的機器學習測資，可以想成是深度學習中的「Hello World!」，它由 60000張 訓練圖片與 10000 張測試圖片所組成，為手寫數字的灰階圖片，大小為 28 * 28 像素，分類 0 到 9 共 10 個數字。
可透過 keras 模組直接取得資料 &gt;&gt;&gt; from tensorflow.keras.datasets import mnist 輸入 mnist.load_data() 可取得 mnist 資料集，回傳值為 2*2 的 tuple of ndarray。 &gt;&gt;&gt; (train_images, train_labels), (test_images, test_labels) = mnist.load_data() tuple 裡面裝載的是 NumPy 的 ndarray 物件，我們可以利用 o.shape 來取得 ndarray 的屬性 len(o) 來取得陣列的個數 &gt;&gt;&gt; train_images.shape (60000, 28, 28) # 3 軸陣列，其大小為 60000 * 28 * 28 &gt;&gt;&gt; test_images.shape (10000, 28, 28) # 3 軸陣列，其大小為 10000 * 28 * 28 &gt;&gt;&gt; len(train_labels), len(test_labels) (60000, 10000) # 訓練集與測試集各有 60000 與 10000 筆 labels &gt;&gt;&gt; train_labels array([5, 0, 4, ..., 5, 6, 8], dtype=uint8) # train_labels 裝 60000 筆資料對應的解答(0-9 的數字) 我們可以利用 matlabplot 把圖片印出來看看 plt.matshow(train_images[0], cmap = plt.get_cmap(&#39;gray&#39;)) plt.show() 用 Dense 層建構神經網路 首先我們需要建立神經網路架構，層(layer)是組成神經網路的基本元件，一個層就是一個資料處理的模組。具體而言，每一層都會從資料中萃取出特定的轉換或表示法，經過數層的資料萃取(data distillation)後，將資料「過瀘」成最後特定的轉換或表達(representation)。
...</p>
  </div>
  <footer class="entry-footer"><span title='2023-10-28 14:11:35 +0800 CST'>October 28, 2023</span>&nbsp;·&nbsp;3 分鐘&nbsp;·&nbsp;Rain Hu</footer>
  <a class="entry-link" aria-label="post link to [ML] sample1 - 手寫數字辨識" href="http://localhost:1313/ml/ex1/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">[ML] Start Tensorflow Environment with Conda
    </h2>
  </header>
  <div class="entry-content">
    <p>環境建置 安裝 Anaconda 創建虛擬環境 conda create -n tensorflow 進入虛擬環境 (macOS/Linux) source activate tensorflow 在環境內安裝 tensorflow pip install tensorflow 在環境內安裝 jupyter notebook pip install jupyter notebook 在環境內安裝 pandas pip install pandas 開啟 jupyter notebook jupyter notebook For terminal user 開始 Anaconda.Navigator 在 Environments 中安裝指定模組 ex.tensorflow, keras 在 terminal 中輸入 conda activate {環境名稱} conda activate tensorflow 開啟 python python 若成功便會顯示 python 安裝資訊
Python 3.11.5 (main, Sep 11 2023, 08:17:37) [Clang 14.0.6 ] on darwin Type &#34;help&#34;, &#34;copyright&#34;, &#34;credits&#34; or &#34;license&#34; for more information. 大功告成，接著嘗試訓練第一筆資料
...</p>
  </div>
  <footer class="entry-footer"><span title='2023-10-11 20:48:34 +0800 CST'>October 11, 2023</span>&nbsp;·&nbsp;1 分鐘&nbsp;·&nbsp;Rain Hu</footer>
  <a class="entry-link" aria-label="post link to [ML] Start Tensorflow Environment with Conda" href="http://localhost:1313/ml/environment/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">[ML] 01. 機器學習基本概念簡介
    </h2>
  </header>
  <div class="entry-content">
    <p>前言 什麼是機器學習 機器學習(Machine Learning)，就是利用機器的力量幫忙找出函式。 Input 可以是 vector matrix sequence Output 可以是 Regression Classification Structed Learning(令機器產生有結構的東西 eg. text, image) 示意圖 什麼是深度學習 深度學習(Deep Learning)，就是利用神經網路(neural network)的方式來產生函數。 機器如何學習 1. 基本原理(訓練三步驟) Step 1: 使用合適的 Model \(y=f(\text{\red{data}})\) Function with unknown parameters Model: \(\boxed{y=b&#43;wx_1}\) \(w: \text{weight}\) \(b: \text{bias}\) \(x: \text{feature}\) Step 2: 定義 Loss function Define loss from training data 以 Model 的參數 \(w,b\) 來計算 Loss 物理意義：Loss 愈大代表參數愈不好，Loss 愈小代表參數愈好。 計算方法：求估計的值與實際的值(label)之間的差距 Loss function: \(\boxed{L=\frac{1}{N}\sum_ne_n}\) MAE (mean absolute error): \(e=|y-\hat{y}|\) MSE (mean square error): \(e=(y-\hat{y})^2\) Cross-entropy: 計算機率分布之間的差距 Error Surface: 根據不同的參數，計算出 loss 所畫出來的等高線圖。 Step 3: Optimization 找到 loss 最小的參數組合 \((w,b)\) 方法：Gradient Descent \(\boxed{w’ = w - \red{\eta}\frac{\partial L}{\partial w}|_{w=w^0,b=b^0}}\) \(\boxed{b’ = b - \red{\eta}\frac{\partial L}{\partial b}|_{w=w^0,b=b^0}}\) \(\red{\eta}\): 學習率 learning rate, 決定 gradient descent 的一步有多大步 2. Linear Model \(\boxed{f\leftarrow y=b&#43;\sum_{j=1}^{n}{w_jx_j}}\) 不只考慮前一天的觀看人數 \(x_1\)，也考慮前二~七天 \(x_2, x_3, … , x_7\)。 當參數變多時，命中率可望有效提升。 3. Piecewise Linear Curves(Sigmoid) \(\text{Sigmoid Function:} \boxed{y=\red{c}\frac{1}{1&#43;e^{-(\green{b}&#43;\blue{w}x_1)}}}=\boxed{\red{c}\text{ sigmoid}(\green{b}&#43;\blue{w}x_1)}\) 將 \(w_ix_i\) 替換成 \(c_i\text{ sigmoid}(b_i&#43;w_ix_i)\) 特徵為1時，\(\boxed{y=b&#43;\sum_i{c_i\text{ sigmoid}(b_i&#43; w_ix_1)}}\) 特徵&gt;1時，\(\boxed{y=b&#43;\sum_i{c_i\text{ sigmoid}(b_i&#43;\sum_j w_{ij}x_j)}}\) 意義：一條曲線可以由多個鋸齒狀的線段(hard sigmoid)的總合，我們可以用 sigmoid 函數來逼近 hard sigmoid。事實上，sigmoid 的個數就是神經網路中一層 neuron 的 node 數，至於使用幾個 sigmoid 是 hyper parameter。 可將公式轉成矩陣計算&#43;激勵函數的形式： 以線性代數方式表示：\(\boxed{y=b&#43;c^T\sigma(b_i&#43;Wx)}\) 將 \(b\)、\(b_i\)、\(W\)、\(c^T\) 等所有參數統稱為 \(\theta\) 故 Loss 可表示成 \(L(\theta)\) 重覆 gradient descent 的方法，更新(update) 參數。 梯度 gradient，\(g=\) \(\begin{bmatrix}\frac{\partial L}{\partial \theta_1}|_{\theta=\theta^0}\\\frac{\partial L}{\partial \theta_2}| _{\theta=\theta^0}\\\vdots\end{bmatrix}=\nabla L(\theta^0)\) 更新(update)計算：\(\begin{bmatrix}\theta_1^1\\\theta_2^1\\\vdots\end{bmatrix}\leftarrow\begin{bmatrix}\theta_1^0\\\theta_2^0\\\vdots\end{bmatrix}-\begin{bmatrix}\eta \frac{\partial L}{\partial \theta_1}|_{\theta=\theta^0}\\\eta\frac{\partial L}{\partial\theta_2}| _{\theta=\theta^0}\\\vdots\end{bmatrix}\) 或寫成 \(\theta^1\leftarrow \theta^0-\eta g\) batch training 將樣本依批次(batch)進行更新，當所有的 batches 都跑過一遍，稱為一個 epoch 4. ReLU 用 hard sigmoid 的方式來表示。 其每一個 hard sigmoid 由兩個 Rectified Linear Unit(ReLU) 組成， 每一個 ReLU 寫成：\(\boxed{\red{c}\text{ max}(0,\green{b}&#43;\blue{w}x_1)}\) 故 Model 可以寫成：\(\boxed{y=b&#43;\sum_{\red{2}i}\text{max}(0,b_i&#43;\sum_j{w_{ij}x_j})}\) 其中我們選用來逼近的函式，稱為 Activation function。 深度學習 Neural Network \(\boxed{y=b&#43;c^T\sigma(b_i&#43;Wx)}\) Multiple hidden layers -&gt; Deep learning </p>
  </div>
  <footer class="entry-footer"><span title='2023-08-02 23:56:25 +0800 CST'>August 2, 2023</span>&nbsp;·&nbsp;2 分鐘&nbsp;·&nbsp;Rain Hu</footer>
  <a class="entry-link" aria-label="post link to [ML] 01. 機器學習基本概念簡介" href="http://localhost:1313/ml/lhy01/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">[ML] 簡單實作測試
    </h2>
  </header>
  <div class="entry-content">
    <p>線性迴歸建模 載入資料 import pandas as pd import matplotlib.pyplot as plt import matplotlib as mlp url = &#34;sample.csv&#34; data = pd.read_csv(url) x = data[&#34;x-axis&#34;] y = data[&#34;y-axis&#34;] 畫圖 def plot(x, y, w, b): line = w * x &#43; b plt.plot(x, line, color=&#34;red&#34;, label=&#34;prediction&#34;) plt.scatter(x, y, color=&#34;blue&#34;, label=&#34;data&#34;, marker=&#34;x&#34;) plt.title(&#34;Title&#34;) plt.xlabel(&#34;x Axis&#34;) plt.ylabel(&#34;y Axis&#34;) plt.xlim([0,12]) plt.ylim([20,140]) plt.show() plot(x, y, 10, 20) 定義 cost function def cost_function(x, y, w, b): y2 = w * x &#43; b cost = (y - y2) ** 2 return cost.mean() cost_function(x, y, 10, 20) 假設在 b = 20 的情形下，找 w 的最小值 w_arr = [] costs = [] for w in range(-100, 101): w2 = 10 &#43; w/100 cost = cost_function(x, y, w2, 20) w_arr.append(w2) costs.append(cost) import matplotlib.pyplot as plt plt.title(&#34;cost function - when b = 20) plt.xlabel(&#34;w&#34;) plt.ylabel(&#34;cost function&#34;) plt.plot(w_arr, costs) plt.show() 利用 numpy 計算矩陣 import numpy as np ws = np.arange(-100, 101) bs = np.arange(-100, 101) costs = np.zeros((201, 201)) i = 0 for w in ws: j = 0 for b in bs: cost = cost_function(x, y, w, b) costs[i,j] = cost j = j&#43;1 i = i&#43;1 print(costs) 畫 3d 圖 ax = plt.axes(projection=&#34;3d&#34;) ax.xaxis.set_pane_color((1,1,1)) ax.yaxis.set_pane_color((1,1,1)) ax.zaxis.set_pane_color((1,1,1)) plt.figure(figsize=(7,7)) ax.view_init(30, -110) b_grid, w_grid = np.meshgrid(bs, ws) ax.plot_surface(w_grid, b_grid, costs, cmap=&#34;Spectral_r&#34;, alpha=0.7) ax.plot_wireframe(w_grid, b_grid, costs, alpha=0.1) ax.set_title(&#34;loss function&#34;) ax.set_xlabel(&#34;w&#34;) ax.set_ylabel(&#34;b&#34;) ax.set_zlabel(&#34;loss&#34;) w_index, b_index = np.where(costs == np.min(costs)) ax.scatter(ws[w_index], bs[b_index], costs[w_index, b_index], color=&#34;red&#34;, s=40) plt.show() 計算梯度 \(\text{cost} = (\text{y}_\text{pred}-\text{y})^2\\ \text{cost} = (\text{y}-(\text{w}\times\text{x}&#43;\text{b}))^2\\ \text{m} _\text{w} = -2\times\text{x}(\text{y-wx-b})\\ \text{m} _\text{b} = -2\times(\text{y-wx-b})\\ \) def compute_gradient(x, y, w, b): w_gradient = 2*x*(w*x&#43;b-y).mean() b_gradient = 2*(w*x&#43;b-y).mean() return w_gradient, b_gradient 利用梯度下降計算 cost 最小值 \(\text{w}_2=\text{w}-\text{m} _\text{w} \times \text{learning\_rate}\) \(\text{b}_2=\text{b}-\text{m} _\text{b} \times \text{learning\_rate}\) learning_rate = 0.001 for i in range(10): w_gradient, b_gradient = compute_gradient(x, y, w, b) w = w - w_gradient * learning_rate b = b - b_gradient * learning_rate cost = cost_function(x, y, w, b) print(f&#34;Iteration {i} : Cost {cost}, w: {w}, b: {b}&#34;) gradient_descent 函式 def gradient_descent(x, y, w_init, b_init, learning_rate, cost_function, gradient_function, run_iteration): c_hist = [] w_hist = [] b_hist = [] w = w_init b = b_init for i in range(run_iteration): w_gradient, b_gradient = gradient_function(x, y, w, b) w = w - w_gradient * learning_rate b = b - b_gradient * learning_rate cost = cost_function(x, y, w, b) w_hist.append(w) b_hist.append(b) c_hist.append(cost) return w, b, w_hist, b_hist, c_hist 多特徵的預測 from sklearn.model_selection import train_test_split scaler = StandardScaler() scaler.fit(x_train) x_train = scaler.transform(x_train) x_test = scaler.transform(x_test) x_real = np.array([[5.3, 2, 1, 0], [7,2, 0, 0, 1]]) x_real = scaler.transfrom(x_real) y_real = (w_final*x_real).sum(axis=1) &#43; b_final y_real 「特徵縮放」加速 gradient descent w1x1&#43;w2x2&#43;w3x3&#43;w4x4&#43;b 因分布範圍不同，調整參數，最好令每一個乘積都相當 相當於是標準化：\(\frac{\text{x-平均值}}{標準差}\) from sklearn.preprocessing import StandardScaler scaler = StandardScaler() scaler.fit(x_train) x_train = scaler.transform(x_train) x_test = scaler.transform(x_test) 邏輯迴歸 Logistic Regression Sigmoid Function 當模性呈現 0-1 關係(邏輯迴歸)時可用 \(\text{Sigmoid Function}=\frac{1}{1&#43;e^{-z}}\) def sigmoid(z): return 1/(1&#43;np.exp(-z)) w = np.array([1,2,3,4]) b = 1 z = (w*x_train).sum(axis=1) &#43; b sigmoid(z) </p>
  </div>
  <footer class="entry-footer"><span title='2023-04-30 00:35:59 +0800 CST'>April 30, 2023</span>&nbsp;·&nbsp;3 分鐘&nbsp;·&nbsp;Rain Hu</footer>
  <a class="entry-link" aria-label="post link to [ML] 簡單實作測試" href="http://localhost:1313/ml/work/"></a>
</article>

<article class="post-entry"> 
<figure class="entry-cover"><img loading="lazy" src="http://localhost:1313/images/cover.jpg" alt="Oh! You closed up the window, so you cannot see raining">
</figure>
  <header class="entry-header">
    <h2 class="entry-hint-parent">[ML] 機器學習與統計學
    </h2>
  </header>
  <div class="entry-content">
    <p>Introduction to ML 統計學與機器學習差在哪裡? 同: 將資料(data)轉為資訊(info)
異: 有無強烈的人為事先假設
統計學
統計學是在資料分析的基礎上，研究如何測定、收集、整理、歸納和分析反映資料，以便給出正確訊息的科學。 機器學習
機器學習演算法是一類從資料中自動分析獲得規律，並利用規律對未知資料進行預測的演算法。 \(\begin{array}{lll} \text{Item} &amp; \text{Statistics} &amp; \text{Machine Learning}\\\hline \text{特性} &amp; \text{伴隨事前假設，依賴明確規則，以模型定義資料關聯性，重視模型解釋性} &amp; \text{幾乎無視前假設，不依賴明確規則，相信經驗}\\ &amp; \text{事前假設(人)}\rightarrow\text{模型估計(機器)} &amp; \text{特徵萃取(機器)}\rightarrow\text{網路建構(機器)} \\\hline \text{優點} &amp; \text{模型可解釋} &amp; \text{不須事先假設或了解資料關聯性}\\ &amp; \text{推論有強烈理論根據} &amp; \text{可抓取資料的所有(幾乎)複雜特徵}\\ &amp; \text{符合事前假設前提下，可做更多的推論}\\ &amp; \text{符合事前假設前提下，不需大量資料} \\\hline \text{缺點} &amp; \text{所有推論接基於事前假設，常難以驗證假設的正確性} &amp; \text{模型難以解釋(黑盒子)}\\ &amp; \text{難以抓取資料中過於複雜的特徵} &amp; \text{推論無強烈理論根據} \\\hline \text{專家} &amp; \text{統計背景} &amp; \text{資訊背景及統計背景} \\\hline \end{array}\) 結論 統計模型的重點是有合理的事前假設 在有合理假設之情況下，統計模型能發揮效力(即使資料量少) 機器學習的重點是大量有代表性的資料 在有大量有效資料之情況下，機器學習能發揮效力(即使人類對資料間的關聯之了解並不多) 何時使用統計方法? 何時使用機器學習? 資料關聯性清楚，容易給予合適的模型假設時，建議使用統計模型 資料無明確規則(如影像及語音辨識)，且資料量夠多時，建議使用機器學習方法(可以佐以人為提示) 統計與機器學習類似的專有名詞 \(\begin{array}{ll} \text{Statistics} &amp; \text{Machine Learning} \text{response, dependent variable} &amp; \text{label} \\\hline \text{covariate, explanatory variable, independent variable} &amp; \text{feature} \\\hline \text{model} &amp; \text{network} \\\hline \text{parameter, coefficient} &amp; \text{weight} \\\hline \text{fitting} &amp; \text{learning} \\\hline \text{refression, classification} &amp; \text{supervised learning} \\\hline \text{density estimation, cluster} &amp; \text{unsupervised learning} \\\hline \end{array}\)
...</p>
  </div>
  <footer class="entry-footer"><span title='2022-11-07 18:18:52 +0800 CST'>November 7, 2022</span>&nbsp;·&nbsp;1 分鐘&nbsp;·&nbsp;Rain Hu</footer>
  <a class="entry-link" aria-label="post link to [ML] 機器學習與統計學" href="http://localhost:1313/ml/lec1/"></a>
</article>

<article class="post-entry"> 
<figure class="entry-cover"><img loading="lazy" src="http://localhost:1313/images/cover.jpg" alt="Oh! You closed up the window, so you cannot see raining">
</figure>
  <header class="entry-header">
    <h2 class="entry-hint-parent">[ML] introduction
    </h2>
  </header>
  <div class="entry-content">
    <p>什麼是 AI &amp; ML &amp; DL 人工智慧是我們想要達成的目標，而機器學習是想要達成目標的手段，希望機器通過學習的方式，變得跟人一樣聰明。 而深度學習就是機器學習的其中一種方法。
人工智慧(Aritificial Intelligence, AI) → 目標 機器學習(Machine Learning, ML) → 手段 深度學習(Deep Learning, DL) … 在機器學習出現之前 生物的行為取決於兩件事，一個是後天學習的結果，一個是天生的本能。
Hand-crafted rules: 人類為機器設定好的天生本能 僵化，無法超越創造者 需要大量人力，不適合小企業 機器學習 寫程式讓機器可以學習 → 尋找關聯資料的函式 舉例：語音辨識、影像辨識、Alpha Go、對話機器人 框架(Framework) 設定一定量的函數 餵入數據 評估函數的好壞 找出最好的函數
\(\begin{array}{rc} \text{step1}&amp;\boxed{\text{Define a set of function}}\\ &amp;\downarrow\\ \text{step2}&amp;\boxed{\text{Evaluate goodness of function}}\\ &amp;\downarrow\\ \text{step3}&amp;\boxed{\text{Pick the best function}}\end{array}\) 告訴機器 input 和正確的 output 這就叫作 supervised learning。 機器學習相關的技術 任務(Task) 迴歸(Regression) Regression 指的是函數的輸出為 scalar(數值)，如 PM2.5。 分類(Classification) Classification 指的是函數的輸出為 東西的類別。 當分類為 Yes or No，則為 Binary Classificatino，如垃圾郵件。 當分類是多個選項的，則為 Multi-Classification，如新聞分類。 結構性學習(Structured Learning) 讓機器的輸出具有結構性。 如語音辨識，聲音訊號為輸入，句子為輸出。 如影像辨識，圖片是輸入，人名是輸出。 方法(Method) 選不同的 function set 就是選不同的 model。
...</p>
  </div>
  <footer class="entry-footer"><span title='2022-06-19 18:18:52 +0800 CST'>June 19, 2022</span>&nbsp;·&nbsp;1 分鐘&nbsp;·&nbsp;Rain Hu</footer>
  <a class="entry-link" aria-label="post link to [ML] introduction" href="http://localhost:1313/ml/lec0/"></a>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://localhost:1313/">Rain Hu&#39;s Workspace</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
