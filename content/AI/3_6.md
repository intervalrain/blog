---
title: "[AI] 3-6. Keras API"
date: 2024-12-20T15:49:27+08:00
tags: ["AI"]
draft: false
Categories: AI
description: "A introduction to Keras API"
author: "Rain Hu"
showToc: true
TocOpen: true
math: true
hidemeta: false
canonicalURL: "https://intervalrain.github.io/"
disableHLJS: true
disableShare: true
disableHLJS: false
hideSummary: false
searchHidden: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowCodeCopyButtons: true
---

## 1. Layer
+ Layer 是神經網路的基本資料處理模組(data-processing module)，可以接受一個或多個張量輸入，再輸出一個或多個張量。Layer 的權重可視為該層的**狀態**(state)，在經過隨機梯度下降法(SGD)不斷更新權重(學習)，最終得到損失值最低的權重值。
### 分類
+ 不同格式的資料需要不同的層來處理。
  + **密集連接層(densely connected layer):** 又稱全連接層(fully connected layer)或密集層(dense layer)。如果資料輸入是簡單的 1D 向量資料，則多半是儲存在 2D 張量中，其 shape 為 (樣本 samples, 特徵 features)，通常是用
  + **循環層(recurrent layer)**: 如果輸入的資料是 2D 序列(sequence) 資料，多半是儲存在 3D 張量中，其 shape 為 (樣本 samples, 時戳 timestamps, 特徵 features)，如 LSTM 層。
  + **2D 卷積層**: 如果是 3D 影像資料，多半是儲存在 4D 張量中，通常使用 2D 卷積層(Conv2D Layer)

### Keras 中的基礎 Layer 類別
+ Layer 類別是 Keras 的核心，每個 Keras 元件都是一個 Layer 物件並與 Layer 有密切互動。Layer 是將一些狀態(權重)和運算(正向傳播)包在一起的物件。
+ 雖然權重可以在建構子 `__init__()` 中建立，但我們通常會使用 `build()` 來建立，然後用 `call()` 來執行正向傳播。
```python
from tensorflow import tf

class SimpleDemo(keras.layers.Layer):
    def __init__(self, units, activation=None):
        super().__init__()
        self.units = units
        self.activation = activation
    
	def build(self, input_shape):
		input_dim = input_shape[-1]
		self.W = self.add_weight(shape=(input_dim, self.units),initializer="random_normal")
		self.b = self.add_weight(shape=(self.units,),initializer="zeros")
	
	def call(self, inputs): 
		y = tf.matmul(inputs, self.W) + self.b
		if self.activation is not None:
			y = self.activation(y)
		return y
```
+ 我們可以像使用函式一樣來實例化 Layer 物件，其輸入為一個張量
```python
sample_layer = SimpleDemo(units=32, activation=tf.nn.relu)
```
+ 建立 `build()` 方法的意義在於，我們希望在第一次呼叫 layer 物件時才即時創建權重張量。
+ keras 會幫我們做好自動推論權重的 shape，我們可以把關注給放在如何定義 `build()`。
```python
model = keras.Sequential([
	SimpleDense(32, activation="relu"),
	SimpleDense(64, activation="relu"),
	SimpleDense(32, activation="relu"),
	SimpleDense(10, activation="softmax")
])
```
+ 事實上 `__call__()` 做的是遠不只推論 shape，還有 **eager 執行模式** 和 **graph 執行模式** 之的路徑選擇等等。

## 2. Model
+ 深度學習模型是由多個層所組成的結構，在 Keras 是以 **Model 類別**來建立模型物件。
+ 目前為止我們只使用過 `Sequential` 類別的模型(序列式模型)，由多個層簡單堆疊而成，有單一的輸入與單一的輸出。
+ 有其他常見的神經網路拓撲，如：
	+ 雙分支神經網路(Two-branch networks): 中間有分支，而非只有線性連接
	+ 多端口網路(Multihead networks): 有多個輸入端或輸出端
	+ 殘差連接(Residual connections): 某些層的輸出會分一條分支跳接到較遠的層
+ Keras 有兩種方式來建構這些非線性模型：
	1. 直接創建 Model 類別的子類別
	2. 使用函數式 API(functional API)

+ 模型的拓撲定義了一個假設空間(hypothesis space)，經由回饋訊號的指引，搜尋有用的輸入資料表示法。選擇完模型拓撲後，接著就是要找出可以發揮最好效果的權重張量。
+ 為了進行訓練，必須做一些假設，這些假設定義了模型可以學到的東西，所以假設空間的結構(模型架構)就變得格外重要，因為它會對現有問題的假設進行編碼，這些假設就是模型開始學習前的**先驗知識(prior knowledge)**

## 3. 編譯
+ 在 compile 之前，要先定義三件事情：
	1. 損失函數(loss function)
	2. 優化器(optimizer)
	3. 評量指標

+ 使用字串的方式定義優化器、損失函數、評量指標
```python
model = keras.Sequential([keras.layers.Dense(1)])
model.compile(optimizer="rmsprop",
							loss="mean_square_error",
							metrics=["accuracy"])
```
+ 使用物件實例的方式定義優化器、損失函數、評量指標
```python
model.compile(optimizer=keras.optimizer.RMSprop(),
						  loss=keras.losses.meanSquaredError(),
							metrics=[keras.metrics.BinaryAccuracy()])
```
+ 物件實例的方法可以用於調整客制化配置
```python
model.compile(optimizer=keras.optimizer.RMSprop(learning_rate=1e-4),
							loss=my_custom_loss,
							metrics=[my_custom_metric_1, my_custom_metric_2])
```

## 4. 選擇損失函數
+ 神經網路在學習過程中，設法降低損常值，所以如果損失函數與要達到的目標無相關時，可能會造成無效的訓練。
+ 二分元類問題: 二元交叉熵(binary crossentropy)
+ 多類別分類問題: 分類交叉熵(categorical crossentropy)

## 5. fit()
+ 輸入(input) 與目標值(targets): 用來訓練的資料，包括輸入樣本和目標答案。資料通常以 NumPy 陣列或 Tensorflow 的 Dataset 物件傳入。
+ 週期數(epochs): 訓練的迴圈數。
+ 批次量(batch_size): 每一週期中，進行小批次梯度下降訓練時的批次量，也就是多少樣本進行一次梯度更新。
+ `fit()` 會回傳一個 History 物件，該物件是一個字典，key 是特定的評量指標名稱，value 是每一週期的損失值或指標值。
```python
history = model.fit(
	inputs,
	targets,
	epochs=5,
	batch_size=128
)
```

## 驗證資料
+ 通常我們會將資料分為「訓練集」與「驗證集」，因為我們的目的並非只在訓練資料上表現良好，也需要在面對新資料時，有良好的預測。
```python
model = keras.Sequential([keras.layers.Dense(1)])
model.compile(optimizer=keras.optimizer.RMSprop(learning_rate=0.1),
   					  loss=keras.losses.MeanSquaredError(),
							metrics=[keras.metrics.BinaryAccuracy()])

# 洗牌
indices_permutation = np.random.permutation(len(inputs))
shuffled_inputs = inputs[indices_permutation]
shuffled_targets = targets[indices_permutation]

# 用 3 成的資料做為驗證集
num_validation_samples = int(0.3 * len(inputs)) 
val_inputs = shuffled_inputs[:num_validation_samples]
val_targets = shuffled_targets[:num_validation_samples]
training_inputs = shuffled_inputs[num_validation_samples]
training_target = shuffled_targets[num_validation_samples]
model.fit(
	training_inputs,
	training_targets,
	epochs=5
	batch_size=16,
	validation_data=(val_inputs, val_targets0)
)
```